{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Young's Modulus Machine Learning Models\n",
    "\n",
    "In this notebook, we train and test 4 machine learning models to predict the Young's modulus from soil cavity simualtions.\n",
    "\n",
    "| **Model**                                                          | **Description**                                                                                                                                                                                     |\n",
    "|-------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Linear Regression with $H$, $d$, $M_w$, $M_c$                                         | Regularized multiple linear regression fitted with two numerical values: cavity depth $H$ and soil density $d$, orientations at the waist ($M_w$) and crown ($M_c$).|\n",
    "| Linear Regression with $H$, $d$, $M_w$, $M_c$, $\\sigma_r$                             | Regularized multiple linear regression fitted with vectorized stress fields $\\sigma_r$ concatenated with $H$ and $d$, orientations at the waist ($M_w$) and crown ($M_c$).|\n",
    "| Convolutional Neural Network with $H$, $d$, $M_w$, $M_c$, and $\\sigma_r$              | Convolutional neural network with 6 hidden layers trained with cavity depth $H$, soil density $d$, orientations at the waist ($M_w$) and crown ($M_c$), and stress field images $\\sigma_r$.   \n",
    "| Mean-score Predictor                                                    | Predict $\\phi$ using the average mean of $\\phi$ scores in the training set.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import cv2\n",
    "\n",
    "from random import sample\n",
    "from scipy.optimize import curve_fit\n",
    "from matplotlib.patches import Ellipse\n",
    "from glob import glob\n",
    "from json import load, dump\n",
    "from os.path import basename\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.style.use('ggplot')\n",
    "from collections import Counter\n",
    "from random import sample\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import scipy.io\n",
    "\n",
    "RANDOM_SEED = 5012021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Create the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder</th>\n",
       "      <th>Depth</th>\n",
       "      <th>d</th>\n",
       "      <th>E</th>\n",
       "      <th>v</th>\n",
       "      <th>phi</th>\n",
       "      <th>psi</th>\n",
       "      <th>c</th>\n",
       "      <th>sv</th>\n",
       "      <th>sh</th>\n",
       "      <th>Delft_inf</th>\n",
       "      <th>Delft_sug</th>\n",
       "      <th>Exists</th>\n",
       "      <th>yield_angle</th>\n",
       "      <th>yield_stress</th>\n",
       "      <th>yield_strain</th>\n",
       "      <th>ID</th>\n",
       "      <th>maxs</th>\n",
       "      <th>Mw</th>\n",
       "      <th>Mc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Disp_0</td>\n",
       "      <td>42</td>\n",
       "      <td>2108.58</td>\n",
       "      <td>49040300</td>\n",
       "      <td>0.292470</td>\n",
       "      <td>44.522842</td>\n",
       "      <td>14.1261</td>\n",
       "      <td>4999.998647</td>\n",
       "      <td>868.777132</td>\n",
       "      <td>259.596199</td>\n",
       "      <td>6113.901626</td>\n",
       "      <td>6089.417004</td>\n",
       "      <td>1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1371.814247</td>\n",
       "      <td>0.053224</td>\n",
       "      <td>1</td>\n",
       "      <td>3889.323653</td>\n",
       "      <td>3.424876e+07</td>\n",
       "      <td>1.716951e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Disp_1</td>\n",
       "      <td>42</td>\n",
       "      <td>2378.76</td>\n",
       "      <td>30544100</td>\n",
       "      <td>0.384267</td>\n",
       "      <td>30.984098</td>\n",
       "      <td>19.1708</td>\n",
       "      <td>4999.998860</td>\n",
       "      <td>980.096695</td>\n",
       "      <td>475.542763</td>\n",
       "      <td>4251.249310</td>\n",
       "      <td>4241.385338</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "      <td>7227.277284</td>\n",
       "      <td>2.259714e+07</td>\n",
       "      <td>6.655354e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disp_10</td>\n",
       "      <td>26</td>\n",
       "      <td>1943.92</td>\n",
       "      <td>54098200</td>\n",
       "      <td>0.277512</td>\n",
       "      <td>31.420224</td>\n",
       "      <td>17.8703</td>\n",
       "      <td>4999.994369</td>\n",
       "      <td>495.816235</td>\n",
       "      <td>237.341833</td>\n",
       "      <td>3442.231579</td>\n",
       "      <td>3367.061231</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>3</td>\n",
       "      <td>5087.393552</td>\n",
       "      <td>4.221634e+07</td>\n",
       "      <td>1.950501e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Disp_100</td>\n",
       "      <td>37</td>\n",
       "      <td>2341.64</td>\n",
       "      <td>98842600</td>\n",
       "      <td>0.302208</td>\n",
       "      <td>36.306435</td>\n",
       "      <td>13.4055</td>\n",
       "      <td>4999.997057</td>\n",
       "      <td>849.945071</td>\n",
       "      <td>346.689454</td>\n",
       "      <td>6781.475357</td>\n",
       "      <td>6706.207493</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>4</td>\n",
       "      <td>4607.743639</td>\n",
       "      <td>7.228302e+07</td>\n",
       "      <td>3.485419e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Disp_1000</td>\n",
       "      <td>18</td>\n",
       "      <td>1794.09</td>\n",
       "      <td>51484900</td>\n",
       "      <td>0.339554</td>\n",
       "      <td>43.157792</td>\n",
       "      <td>14.0802</td>\n",
       "      <td>5000.006868</td>\n",
       "      <td>316.800412</td>\n",
       "      <td>100.105789</td>\n",
       "      <td>3325.922880</td>\n",
       "      <td>3142.177730</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>527.343236</td>\n",
       "      <td>0.022421</td>\n",
       "      <td>5</td>\n",
       "      <td>1593.593864</td>\n",
       "      <td>3.405497e+07</td>\n",
       "      <td>1.689281e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Folder  Depth        d         E         v        phi      psi  \\\n",
       "0     Disp_0     42  2108.58  49040300  0.292470  44.522842  14.1261   \n",
       "1     Disp_1     42  2378.76  30544100  0.384267  30.984098  19.1708   \n",
       "2    Disp_10     26  1943.92  54098200  0.277512  31.420224  17.8703   \n",
       "3   Disp_100     37  2341.64  98842600  0.302208  36.306435  13.4055   \n",
       "4  Disp_1000     18  1794.09  51484900  0.339554  43.157792  14.0802   \n",
       "\n",
       "             c          sv          sh    Delft_inf    Delft_sug  Exists  \\\n",
       "0  4999.998647  868.777132  259.596199  6113.901626  6089.417004       1   \n",
       "1  4999.998860  980.096695  475.542763  4251.249310  4241.385338       1   \n",
       "2  4999.994369  495.816235  237.341833  3442.231579  3367.061231       1   \n",
       "3  4999.997057  849.945071  346.689454  6781.475357  6706.207493       1   \n",
       "4  5000.006868  316.800412  100.105789  3325.922880  3142.177730       1   \n",
       "\n",
       "   yield_angle  yield_stress  yield_strain  ID         maxs            Mw  \\\n",
       "0         45.0   1371.814247      0.053224   1  3889.323653  3.424876e+07   \n",
       "1          NaN           inf           inf   2  7227.277284  2.259714e+07   \n",
       "2          NaN           inf           inf   3  5087.393552  4.221634e+07   \n",
       "3          NaN           inf           inf   4  4607.743639  7.228302e+07   \n",
       "4         40.0    527.343236      0.022421   5  1593.593864  3.405497e+07   \n",
       "\n",
       "             Mc  \n",
       "0  1.716951e+07  \n",
       "1  6.655354e+06  \n",
       "2  1.950501e+07  \n",
       "3  3.485419e+07  \n",
       "4  1.689281e+07  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df = pd.read_csv('./data/data-10-12/Disp_Output.csv')\n",
    "input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/zwang3049/jay/miniconda3/envs/nlp/lib/python3.8/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "feature_df = input_df.iloc[:, [0, 1, 2, 3, 4, 5, 6, 8, 9, 14, 18, 19]]\n",
    "feature_df.loc[:, 'phi'] = np.sin(feature_df['phi'])\n",
    "feature_df.loc[:, 'psi'] = np.sin(feature_df['psi'])\n",
    "\n",
    "# Need to handle the nan cases in the last feature\n",
    "max_stress = list(np.sort(list(set(feature_df['yield_stress']))))[-2] * 1.2\n",
    "feature_df.loc[:, 'yield_stress'] = [x if x != np.inf else max_stress for x in\n",
    "                                     feature_df['yield_stress']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder</th>\n",
       "      <th>Depth</th>\n",
       "      <th>d</th>\n",
       "      <th>E</th>\n",
       "      <th>v</th>\n",
       "      <th>phi</th>\n",
       "      <th>psi</th>\n",
       "      <th>sv</th>\n",
       "      <th>sh</th>\n",
       "      <th>yield_stress</th>\n",
       "      <th>Mw</th>\n",
       "      <th>Mc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Disp_0</td>\n",
       "      <td>42</td>\n",
       "      <td>2108.58</td>\n",
       "      <td>49040300</td>\n",
       "      <td>0.292470</td>\n",
       "      <td>0.514604</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>868.777132</td>\n",
       "      <td>259.596199</td>\n",
       "      <td>1371.814247</td>\n",
       "      <td>3.424876e+07</td>\n",
       "      <td>1.716951e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Disp_1</td>\n",
       "      <td>42</td>\n",
       "      <td>2378.76</td>\n",
       "      <td>30544100</td>\n",
       "      <td>0.384267</td>\n",
       "      <td>-0.418532</td>\n",
       "      <td>0.315747</td>\n",
       "      <td>980.096695</td>\n",
       "      <td>475.542763</td>\n",
       "      <td>12599.315984</td>\n",
       "      <td>2.259714e+07</td>\n",
       "      <td>6.655354e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disp_10</td>\n",
       "      <td>26</td>\n",
       "      <td>1943.92</td>\n",
       "      <td>54098200</td>\n",
       "      <td>0.277512</td>\n",
       "      <td>0.004298</td>\n",
       "      <td>-0.830083</td>\n",
       "      <td>495.816235</td>\n",
       "      <td>237.341833</td>\n",
       "      <td>12599.315984</td>\n",
       "      <td>4.221634e+07</td>\n",
       "      <td>1.950501e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Disp_100</td>\n",
       "      <td>37</td>\n",
       "      <td>2341.64</td>\n",
       "      <td>98842600</td>\n",
       "      <td>0.302208</td>\n",
       "      <td>-0.984179</td>\n",
       "      <td>0.744062</td>\n",
       "      <td>849.945071</td>\n",
       "      <td>346.689454</td>\n",
       "      <td>12599.315984</td>\n",
       "      <td>7.228302e+07</td>\n",
       "      <td>3.485419e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Disp_1000</td>\n",
       "      <td>18</td>\n",
       "      <td>1794.09</td>\n",
       "      <td>51484900</td>\n",
       "      <td>0.339554</td>\n",
       "      <td>-0.734212</td>\n",
       "      <td>0.998378</td>\n",
       "      <td>316.800412</td>\n",
       "      <td>100.105789</td>\n",
       "      <td>527.343236</td>\n",
       "      <td>3.405497e+07</td>\n",
       "      <td>1.689281e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>Disp_994</td>\n",
       "      <td>32</td>\n",
       "      <td>2229.42</td>\n",
       "      <td>40226900</td>\n",
       "      <td>0.357334</td>\n",
       "      <td>-0.965397</td>\n",
       "      <td>0.375137</td>\n",
       "      <td>699.859526</td>\n",
       "      <td>417.146417</td>\n",
       "      <td>12599.315984</td>\n",
       "      <td>3.009717e+07</td>\n",
       "      <td>4.791700e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>Disp_995</td>\n",
       "      <td>22</td>\n",
       "      <td>2193.27</td>\n",
       "      <td>32543800</td>\n",
       "      <td>0.303484</td>\n",
       "      <td>-0.817674</td>\n",
       "      <td>-0.482105</td>\n",
       "      <td>473.351531</td>\n",
       "      <td>288.790019</td>\n",
       "      <td>12599.315984</td>\n",
       "      <td>2.530108e+07</td>\n",
       "      <td>3.844875e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>Disp_996</td>\n",
       "      <td>23</td>\n",
       "      <td>1840.08</td>\n",
       "      <td>91644200</td>\n",
       "      <td>0.367731</td>\n",
       "      <td>0.991931</td>\n",
       "      <td>0.814962</td>\n",
       "      <td>415.177250</td>\n",
       "      <td>189.909436</td>\n",
       "      <td>1856.090156</td>\n",
       "      <td>6.426574e+07</td>\n",
       "      <td>3.248387e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>Disp_997</td>\n",
       "      <td>26</td>\n",
       "      <td>2175.94</td>\n",
       "      <td>47073400</td>\n",
       "      <td>0.380248</td>\n",
       "      <td>0.908312</td>\n",
       "      <td>-0.569548</td>\n",
       "      <td>554.995256</td>\n",
       "      <td>301.867349</td>\n",
       "      <td>12599.315984</td>\n",
       "      <td>3.444246e+07</td>\n",
       "      <td>9.688675e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>Disp_999</td>\n",
       "      <td>33</td>\n",
       "      <td>1628.34</td>\n",
       "      <td>90986400</td>\n",
       "      <td>0.337591</td>\n",
       "      <td>-0.987454</td>\n",
       "      <td>-0.880661</td>\n",
       "      <td>527.142508</td>\n",
       "      <td>317.760475</td>\n",
       "      <td>12599.315984</td>\n",
       "      <td>6.774978e+07</td>\n",
       "      <td>2.764555e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1363 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Folder  Depth        d         E         v       phi       psi  \\\n",
       "0        Disp_0     42  2108.58  49040300  0.292470  0.514604  0.999939   \n",
       "1        Disp_1     42  2378.76  30544100  0.384267 -0.418532  0.315747   \n",
       "2       Disp_10     26  1943.92  54098200  0.277512  0.004298 -0.830083   \n",
       "3      Disp_100     37  2341.64  98842600  0.302208 -0.984179  0.744062   \n",
       "4     Disp_1000     18  1794.09  51484900  0.339554 -0.734212  0.998378   \n",
       "...         ...    ...      ...       ...       ...       ...       ...   \n",
       "1358   Disp_994     32  2229.42  40226900  0.357334 -0.965397  0.375137   \n",
       "1359   Disp_995     22  2193.27  32543800  0.303484 -0.817674 -0.482105   \n",
       "1360   Disp_996     23  1840.08  91644200  0.367731  0.991931  0.814962   \n",
       "1361   Disp_997     26  2175.94  47073400  0.380248  0.908312 -0.569548   \n",
       "1362   Disp_999     33  1628.34  90986400  0.337591 -0.987454 -0.880661   \n",
       "\n",
       "              sv          sh  yield_stress            Mw            Mc  \n",
       "0     868.777132  259.596199   1371.814247  3.424876e+07  1.716951e+07  \n",
       "1     980.096695  475.542763  12599.315984  2.259714e+07  6.655354e+06  \n",
       "2     495.816235  237.341833  12599.315984  4.221634e+07  1.950501e+07  \n",
       "3     849.945071  346.689454  12599.315984  7.228302e+07  3.485419e+07  \n",
       "4     316.800412  100.105789    527.343236  3.405497e+07  1.689281e+07  \n",
       "...          ...         ...           ...           ...           ...  \n",
       "1358  699.859526  417.146417  12599.315984  3.009717e+07  4.791700e+06  \n",
       "1359  473.351531  288.790019  12599.315984  2.530108e+07  3.844875e+06  \n",
       "1360  415.177250  189.909436   1856.090156  6.426574e+07  3.248387e+07  \n",
       "1361  554.995256  301.867349  12599.315984  3.444246e+07  9.688675e+06  \n",
       "1362  527.142508  317.760475  12599.315984  6.774978e+07  2.764555e+07  \n",
       "\n",
       "[1363 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df_normalized = feature_df.copy()\n",
    "feature_df_normalized\n",
    "\n",
    "# feature_js = [1, 2, 3, 4, 7, 8]\n",
    "feature_js = [1, 2, 4, 7, 8, 10, 11]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(feature_df.iloc[:, feature_js])\n",
    "feature_df_normalized.iloc[:, feature_js] = scaler.transform(feature_df.iloc[:, feature_js])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder</th>\n",
       "      <th>Depth</th>\n",
       "      <th>d</th>\n",
       "      <th>E</th>\n",
       "      <th>v</th>\n",
       "      <th>phi</th>\n",
       "      <th>psi</th>\n",
       "      <th>sv</th>\n",
       "      <th>sh</th>\n",
       "      <th>yield_stress</th>\n",
       "      <th>Mw</th>\n",
       "      <th>Mc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Disp_0</td>\n",
       "      <td>1.096189</td>\n",
       "      <td>0.494497</td>\n",
       "      <td>49040300</td>\n",
       "      <td>-0.810510</td>\n",
       "      <td>0.514604</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>1.229796</td>\n",
       "      <td>0.108418</td>\n",
       "      <td>1371.814247</td>\n",
       "      <td>-0.873115</td>\n",
       "      <td>-0.391815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Disp_1</td>\n",
       "      <td>1.096189</td>\n",
       "      <td>1.661630</td>\n",
       "      <td>30544100</td>\n",
       "      <td>1.336013</td>\n",
       "      <td>-0.418532</td>\n",
       "      <td>0.315747</td>\n",
       "      <td>1.630156</td>\n",
       "      <td>1.614973</td>\n",
       "      <td>12599.315984</td>\n",
       "      <td>-1.681844</td>\n",
       "      <td>-1.683193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disp_10</td>\n",
       "      <td>-0.066483</td>\n",
       "      <td>-0.216807</td>\n",
       "      <td>54098200</td>\n",
       "      <td>-1.160278</td>\n",
       "      <td>0.004298</td>\n",
       "      <td>-0.830083</td>\n",
       "      <td>-0.111556</td>\n",
       "      <td>-0.046840</td>\n",
       "      <td>12599.315984</td>\n",
       "      <td>-0.320092</td>\n",
       "      <td>-0.104962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Disp_100</td>\n",
       "      <td>0.732854</td>\n",
       "      <td>1.501277</td>\n",
       "      <td>98842600</td>\n",
       "      <td>-0.582803</td>\n",
       "      <td>-0.984179</td>\n",
       "      <td>0.744062</td>\n",
       "      <td>1.162067</td>\n",
       "      <td>0.716026</td>\n",
       "      <td>12599.315984</td>\n",
       "      <td>1.766810</td>\n",
       "      <td>1.780266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Disp_1000</td>\n",
       "      <td>-0.647818</td>\n",
       "      <td>-0.864047</td>\n",
       "      <td>51484900</td>\n",
       "      <td>0.290473</td>\n",
       "      <td>-0.734212</td>\n",
       "      <td>0.998378</td>\n",
       "      <td>-0.755385</td>\n",
       "      <td>-1.004269</td>\n",
       "      <td>527.343236</td>\n",
       "      <td>-0.886566</td>\n",
       "      <td>-0.425800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>Disp_994</td>\n",
       "      <td>0.369519</td>\n",
       "      <td>1.016506</td>\n",
       "      <td>40226900</td>\n",
       "      <td>0.706229</td>\n",
       "      <td>-0.965397</td>\n",
       "      <td>0.375137</td>\n",
       "      <td>0.622285</td>\n",
       "      <td>1.207570</td>\n",
       "      <td>12599.315984</td>\n",
       "      <td>-1.161273</td>\n",
       "      <td>-1.912092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>Disp_995</td>\n",
       "      <td>-0.357150</td>\n",
       "      <td>0.860344</td>\n",
       "      <td>32543800</td>\n",
       "      <td>-0.552965</td>\n",
       "      <td>-0.817674</td>\n",
       "      <td>-0.482105</td>\n",
       "      <td>-0.192350</td>\n",
       "      <td>0.312089</td>\n",
       "      <td>12599.315984</td>\n",
       "      <td>-1.494165</td>\n",
       "      <td>-2.028383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>Disp_996</td>\n",
       "      <td>-0.284483</td>\n",
       "      <td>-0.665378</td>\n",
       "      <td>91644200</td>\n",
       "      <td>0.949346</td>\n",
       "      <td>0.991931</td>\n",
       "      <td>0.814962</td>\n",
       "      <td>-0.401573</td>\n",
       "      <td>-0.377753</td>\n",
       "      <td>1856.090156</td>\n",
       "      <td>1.210337</td>\n",
       "      <td>1.489137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>Disp_997</td>\n",
       "      <td>-0.066483</td>\n",
       "      <td>0.785481</td>\n",
       "      <td>47073400</td>\n",
       "      <td>1.242035</td>\n",
       "      <td>0.908312</td>\n",
       "      <td>-0.569548</td>\n",
       "      <td>0.101281</td>\n",
       "      <td>0.403323</td>\n",
       "      <td>12599.315984</td>\n",
       "      <td>-0.859671</td>\n",
       "      <td>-1.310632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>Disp_999</td>\n",
       "      <td>0.442186</td>\n",
       "      <td>-1.580060</td>\n",
       "      <td>90986400</td>\n",
       "      <td>0.244571</td>\n",
       "      <td>-0.987454</td>\n",
       "      <td>-0.880661</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.514202</td>\n",
       "      <td>12599.315984</td>\n",
       "      <td>1.452162</td>\n",
       "      <td>0.894881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1363 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Folder     Depth         d         E         v       phi       psi  \\\n",
       "0        Disp_0  1.096189  0.494497  49040300 -0.810510  0.514604  0.999939   \n",
       "1        Disp_1  1.096189  1.661630  30544100  1.336013 -0.418532  0.315747   \n",
       "2       Disp_10 -0.066483 -0.216807  54098200 -1.160278  0.004298 -0.830083   \n",
       "3      Disp_100  0.732854  1.501277  98842600 -0.582803 -0.984179  0.744062   \n",
       "4     Disp_1000 -0.647818 -0.864047  51484900  0.290473 -0.734212  0.998378   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "1358   Disp_994  0.369519  1.016506  40226900  0.706229 -0.965397  0.375137   \n",
       "1359   Disp_995 -0.357150  0.860344  32543800 -0.552965 -0.817674 -0.482105   \n",
       "1360   Disp_996 -0.284483 -0.665378  91644200  0.949346  0.991931  0.814962   \n",
       "1361   Disp_997 -0.066483  0.785481  47073400  1.242035  0.908312 -0.569548   \n",
       "1362   Disp_999  0.442186 -1.580060  90986400  0.244571 -0.987454 -0.880661   \n",
       "\n",
       "            sv        sh  yield_stress        Mw        Mc  \n",
       "0     1.229796  0.108418   1371.814247 -0.873115 -0.391815  \n",
       "1     1.630156  1.614973  12599.315984 -1.681844 -1.683193  \n",
       "2    -0.111556 -0.046840  12599.315984 -0.320092 -0.104962  \n",
       "3     1.162067  0.716026  12599.315984  1.766810  1.780266  \n",
       "4    -0.755385 -1.004269    527.343236 -0.886566 -0.425800  \n",
       "...        ...       ...           ...       ...       ...  \n",
       "1358  0.622285  1.207570  12599.315984 -1.161273 -1.912092  \n",
       "1359 -0.192350  0.312089  12599.315984 -1.494165 -2.028383  \n",
       "1360 -0.401573 -0.377753   1856.090156  1.210337  1.489137  \n",
       "1361  0.101281  0.403323  12599.315984 -0.859671 -1.310632  \n",
       "1362  0.001109  0.514202  12599.315984  1.452162  0.894881  \n",
       "\n",
       "[1363 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize E using the min and max values\n",
    "e_range = np.max(feature_df['E']) - np.min(feature_df['E'])\n",
    "e_min = np.min(feature_df['E'])\n",
    "feature_df_normalized['norm_E'] = (feature_df_normalized['E'] - np.min(feature_df['E'])) / e_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_image_data = np.load('./data/displayment-heatmaps-normalized-resized.npz')\n",
    "heatmaps_images = heatmap_image_data['rs_normalized_heatmaps']\n",
    "heatmaps_ids = heatmap_image_data['heatmaps_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1363, 256, 256)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heatmaps_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = [int(x[5:]) for x in feature_df['Folder']]\n",
    "indexes.index(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(feature_df_normalized['norm_E'], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1363/1363 [00:00<00:00, 1656.31it/s]\n",
      "/tmp/ipykernel_7240/2091989803.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  features = np.array(features)\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "scores = []\n",
    "\n",
    "for i in tqdm(range(len(heatmaps_ids))):\n",
    "    df_i = indexes.index(heatmaps_ids[i])\n",
    "    \n",
    "    # Collect the features\n",
    "    row = feature_df_normalized.iloc[df_i, :]\n",
    "    cur_features = row[['Depth', 'd', 'Mw', 'Mc']].to_numpy().astype(float)\n",
    "    features.append((heatmaps_images[i], cur_features))\n",
    "    \n",
    "    # Collect the y's\n",
    "    scores.append(row['norm_E'])\n",
    "\n",
    "features = np.array(features)\n",
    "scores = np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(817, 2) (817,) (273, 2) (273,) (273, 2) (273,)\n"
     ]
    }
   ],
   "source": [
    "train_features, temp_features, train_scores, temp_scores = train_test_split(\n",
    "    features, scores, train_size=0.6, random_state=RANDOM_SEED)\n",
    "vali_features, test_features, vali_scores, test_scores = train_test_split(\n",
    "    temp_features, temp_scores, train_size=0.5, random_state=RANDOM_SEED)\n",
    "\n",
    "print(train_features.shape, train_scores.shape,\n",
    "      vali_features.shape, vali_scores.shape,\n",
    "      test_features.shape, test_scores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear regression with Depth + Density + Mw + Mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 817/817 [00:00<00:00, 534427.07it/s]\n",
      "100%|█████████████████████████████████████| 273/273 [00:00<00:00, 483958.15it/s]\n",
      "100%|█████████████████████████████████████| 273/273 [00:00<00:00, 495905.15it/s]\n"
     ]
    }
   ],
   "source": [
    "train_features_linear = []\n",
    "vali_features_linear = []\n",
    "test_features_linear = []\n",
    "\n",
    "for i in tqdm(range(train_features.shape[0])):    \n",
    "    train_features_linear.append(train_features[i][1].reshape(-1))\n",
    "    \n",
    "for i in tqdm(range(vali_features.shape[0])):\n",
    "    vali_features_linear.append(vali_features[i][1].reshape(-1))\n",
    "    \n",
    "for i in tqdm(range(test_features.shape[0])):\n",
    "    test_features_linear.append(test_features[i][1].reshape(-1))\n",
    "    \n",
    "train_features_linear = np.vstack(train_features_linear)\n",
    "vali_features_linear = np.vstack(vali_features_linear)\n",
    "test_features_linear = np.vstack(test_features_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(817, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_linear.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search the regularization power over validation set (Lasso regression)\n",
    "\n",
    "# model = linear_model.Lasso()\n",
    "# params = [{'alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}]\n",
    "# clf = GridSearchCV(model, params, scoring='neg_mean_absolute_error')\n",
    "# clf.fit(naive_train_features, train_scores)\n",
    "\n",
    "# print(clf.cv_results_)\n",
    "# print(clf.best_params_)\n",
    "# print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.0001)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.Lasso(alpha=0.0001)\n",
    "model.fit(train_features_linear, train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_sklearn(model, x, y, title=''):\n",
    "    y_predict = model.predict(x)\n",
    "    \n",
    "    mse = metrics.mean_squared_error(y, y_predict)\n",
    "    mae = metrics.mean_absolute_error(y, y_predict)\n",
    "    \n",
    "    mape = metrics.mean_absolute_percentage_error(\n",
    "        [e_min + e_range * i for i in y],\n",
    "        [e_min + e_range * i for i in y_predict]\n",
    "    )\n",
    "    \n",
    "    print('{}\\tMSE: {:.4f}  MAE: {:.4f}  MAPE: {:.4f}'.format(title, mse, mae, mape))\n",
    "    \n",
    "    return mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\tMSE: 0.0025  MAE: 0.0391  MAPE: 0.0425\n",
      "vali\tMSE: 0.0028  MAE: 0.0421  MAPE: 0.0432\n",
      "test\tMSE: 0.0025  MAE: 0.0387  MAPE: 0.0418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0025044161928919092, 0.038707832583415744)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model_sklearn(model, train_features_linear, train_scores, 'train')\n",
    "eval_model_sklearn(model, vali_features_linear, vali_scores, 'vali')\n",
    "eval_model_sklearn(model, test_features_linear, test_scores, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Model with Depth + Density + Mw + Mc + Simulation Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 817/817 [00:00<00:00, 3227.41it/s]\n",
      "100%|███████████████████████████████████████| 273/273 [00:00<00:00, 3272.48it/s]\n",
      "100%|███████████████████████████████████████| 273/273 [00:00<00:00, 3433.47it/s]\n"
     ]
    }
   ],
   "source": [
    "train_features_linear = []\n",
    "vali_features_linear = []\n",
    "test_features_linear = []\n",
    "\n",
    "for i in tqdm(range(train_features.shape[0])):\n",
    "    cur_feature = train_features[i][0].reshape(-1)\n",
    "    cur_feature = np.concatenate([cur_feature, train_features[i][1].reshape(-1)])\n",
    "    \n",
    "    train_features_linear.append(cur_feature)\n",
    "    \n",
    "for i in tqdm(range(vali_features.shape[0])):\n",
    "    cur_feature = vali_features[i][0].reshape(-1)\n",
    "    cur_feature = np.concatenate([cur_feature, vali_features[i][1].reshape(-1)])\n",
    "    \n",
    "    vali_features_linear.append(cur_feature)\n",
    "    \n",
    "for i in tqdm(range(test_features.shape[0])):\n",
    "    cur_feature = test_features[i][0].reshape(-1)\n",
    "    cur_feature = np.concatenate([cur_feature, test_features[i][1].reshape(-1)])\n",
    "    \n",
    "    test_features_linear.append(cur_feature)\n",
    "    \n",
    "train_features_linear = np.vstack(train_features_linear)\n",
    "vali_features_linear = np.vstack(vali_features_linear)\n",
    "test_features_linear = np.vstack(test_features_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(817, 65540)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_linear.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(817,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_features_linear)\n",
    "\n",
    "train_features_linear_standardized = scaler.transform(train_features_linear)\n",
    "vali_features_linear_standardized = scaler.transform(vali_features_linear)\n",
    "test_features_linear_standardized = scaler.transform(test_features_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search the regularization power over validation set (Lasso regression)\n",
    "\n",
    "# model = linear_model.Lasso()\n",
    "# params = [{'alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}]\n",
    "# clf = GridSearchCV(model, params, scoring='neg_mean_absolute_error')\n",
    "# clf.fit(naive_train_features, train_scores)\n",
    "\n",
    "# print(clf.cv_results_)\n",
    "# print(clf.best_params_)\n",
    "# print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/zwang3049/jay/miniconda3/envs/nlp/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.021352178320096282, tolerance: 0.006940413142613379\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.0001, max_iter=10000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.Lasso(alpha=0.0001, max_iter=10000)\n",
    "model.fit(train_features_linear_standardized, train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_sklearn(model, x, y, title=''):\n",
    "    y_predict = model.predict(x)\n",
    "    \n",
    "    mse = metrics.mean_squared_error(y, y_predict)\n",
    "    mae = metrics.mean_absolute_error(y, y_predict)\n",
    "    \n",
    "    mape = metrics.mean_absolute_percentage_error(\n",
    "        [e_min + e_range * i for i in y],\n",
    "        [e_min + e_range * i for i in y_predict]\n",
    "    )\n",
    "    \n",
    "    print('{}\\tMSE: {:.4f}  MAE: {:.4f}  MAPE: {:.4f}'.format(title, mse, mae, mape))\n",
    "    \n",
    "    return mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\tMSE: 0.0008  MAE: 0.0219  MAPE: 0.0246\n",
      "vali\tMSE: 0.0009  MAE: 0.0238  MAPE: 0.0257\n",
      "test\tMSE: 0.0009  MAE: 0.0230  MAPE: 0.0268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0008995232953816017, 0.0230433916054929)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model_sklearn(model, train_features_linear_standardized, train_scores, 'train')\n",
    "eval_model_sklearn(model, vali_features_linear_standardized, vali_scores, 'vali')\n",
    "eval_model_sklearn(model, test_features_linear_standardized, test_scores, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CNN Model with Depth + Density + Mw + Mc + Simulation Output\n",
    "\n",
    "### 3.1 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, additional_feature_size):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.additional_feature_size = additional_feature_size\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)     \n",
    "        self.conv2 = nn.Conv2d(6, 6, 3)\n",
    "        self.pool1= nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(6, 6, 3)\n",
    "        self.conv4 = nn.Conv2d(6, 6, 3)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(6, 6, 3)\n",
    "        self.conv6 = nn.Conv2d(6, 6, 3)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(6 * 28 * 28 + self.additional_feature_size, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 1)\n",
    "\n",
    "    def forward(self, image, feature):\n",
    "        image = image.view(-1, 1, 256, 256)\n",
    "        \n",
    "        # Passing the CNN layers\n",
    "        x = F.relu(self.conv1(image))\n",
    "        x = self.pool1(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool2(F.relu(self.conv4(x)))\n",
    "        \n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.pool3(F.relu(self.conv6(x)))\n",
    "                \n",
    "        x = x.view(-1, 6 * 28 * 28)\n",
    "        \n",
    "        # Concatenate with extra features\n",
    "        x = torch.cat((x, feature), dim=1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        # x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/zwang3049/jay/miniconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0957]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device('cpu')\n",
    "\n",
    "model = SimpleCNN(0)\n",
    "image = torch.tensor([features[0][0]]).float().to(device)\n",
    "feature = torch.tensor([features[0][1]]).float().to(device)[:, []]\n",
    "model = model.to(device)\n",
    "model(image, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeatmapDataset(Dataset):\n",
    "\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        cur_feature = self.features[idx]\n",
    "        # label = nn.functional.one_hot(torch.tensor(labels[idx]), num_classes=3)\n",
    "        label = torch.tensor([self.labels[idx]]).float()\n",
    "        \n",
    "        # Load image and extra feature\n",
    "        image = torch.tensor(cur_feature[0]).float()\n",
    "        extra_feature = torch.tensor(cur_feature[1]).float()\n",
    "        \n",
    "        # Transform image\n",
    "        image = image.view((1, 256, 256))\n",
    "        \n",
    "        sample = {'image': image, 'feature': extra_feature, 'label': label}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HeatmapDataset(train_features, train_scores)\n",
    "vali_dataset = HeatmapDataset(vali_features, vali_scores)\n",
    "test_dataset = HeatmapDataset(test_features, test_scores)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "vali_dataloader = DataLoader(vali_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(train_dataloader, epoch, print_every_ter=None, verbose=True,\n",
    "                   selected_indexes=None):\n",
    "    losses = []\n",
    "    all_losses = []\n",
    "    y_predict = []\n",
    "    y_true = []\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        cur_images, cur_features, cur_labels = (data['image'].to(device),\n",
    "                                                data['feature'].to(device),\n",
    "                                                data['label'].to(device))\n",
    "        \n",
    "        # Only use depth and d here\n",
    "        if selected_indexes != None:\n",
    "            cur_features = cur_features[:, selected_indexes]\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(cur_images, cur_features)\n",
    "        loss = criterion(outputs, cur_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        y_predict.extend(outputs.tolist())\n",
    "        y_true.extend(cur_labels.tolist())\n",
    "\n",
    "        # print statistics\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if print_every_ter != None:\n",
    "            if i % print_every_ter == print_every_ter - 1:\n",
    "                print('(epoch {}, iter {}) avg loss: {:3f}'.format(epoch + 1,\n",
    "                                                                   i + 1,\n",
    "                                                                   np.mean(losses)))\n",
    "                all_losses.extend(losses)\n",
    "                losses = []\n",
    "        else:\n",
    "            all_losses.append(loss.item())\n",
    "    \n",
    "    # Evaluate the accuracy\n",
    "    mse = metrics.mean_squared_error(y_true, y_predict)\n",
    "    avg_loss = np.mean(all_losses)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Epoch {}: training acc: {:.4f} avg loss: {:.4f}'.format(epoch, acc, avg_loss))\n",
    "\n",
    "    return mse, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(test_dataloader, model, selected_indexes=None, l1_error=False):\n",
    "    losses = []\n",
    "    y_predict = []\n",
    "    y_true = []\n",
    "\n",
    "    for i, data in enumerate(test_dataloader, 0):\n",
    "        cur_images, cur_features, cur_labels = (data['image'].to(device),\n",
    "                                                data['feature'].to(device),\n",
    "                                                data['label'].to(device))\n",
    "        \n",
    "        # Only use depth and d here\n",
    "        if selected_indexes != None:\n",
    "            cur_features = cur_features[:, selected_indexes]\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(cur_images, cur_features)\n",
    "        loss = criterion(outputs, cur_labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        y_predict.extend(outputs.tolist())\n",
    "        y_true.extend(cur_labels.tolist())\n",
    "    \n",
    "    mse = metrics.mean_squared_error(y_true, y_predict)\n",
    "    mae = metrics.mean_absolute_error(y_true, y_predict)\n",
    "    avg_loss = np.mean(losses)\n",
    "    \n",
    "    #print('Test accuracy {:.4f} test avg loss {:.4f}'.format(acc, avg_loss))\n",
    "    \n",
    "    if not l1_error:\n",
    "        return mse, avg_loss\n",
    "    else:\n",
    "        return mae, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████▎                           | 615/2000 [20:11<45:27,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "PATIENCE = 200\n",
    "epochs = 2000\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "selected_indexes = [0, 1, 2, 3]\n",
    "\n",
    "model = SimpleCNN(len(selected_indexes)).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "lr = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train_mses = []\n",
    "train_avg_losses = []\n",
    "\n",
    "val_mses = []\n",
    "val_avg_losses = []\n",
    "\n",
    "best_loss = np.inf\n",
    "best_mse = np.inf\n",
    "waited = 0\n",
    "best_model = None\n",
    "\n",
    "for e in tqdm(range(epochs)):\n",
    "    mse, avg_loss = train_one_epoch(train_dataloader, e, verbose=False,\n",
    "                                    selected_indexes=selected_indexes)\n",
    "    train_mses.append(mse)\n",
    "    train_avg_losses.append(avg_loss)\n",
    "    \n",
    "    # Test on the validation set\n",
    "    val_mse, val_avg_loss = eval_model(vali_dataloader, model,\n",
    "                                       selected_indexes=selected_indexes)\n",
    "    val_mses.append(val_mse)\n",
    "    val_avg_losses.append(val_avg_loss)\n",
    "    \n",
    "    if val_mse < best_mse:\n",
    "        # best_loss = val_avg_loss\n",
    "        best_mse = val_mse\n",
    "        waited = 0\n",
    "        best_model = copy.deepcopy(model)\n",
    "    else:\n",
    "        waited += 1\n",
    "    \n",
    "    if waited == PATIENCE + 1:\n",
    "        break\n",
    "\n",
    "print('Done!')\n",
    "torch.save(best_model.state_dict(), './model/cnn-e-extra.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model Evaluation\n",
    "\n",
    "Since we have normalzied the E, the performance is not very easy to interpret. Here we transform the predicted E to their original scale, and then compute performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "lr = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "selected_indexes = [0, 1, 2, 3]\n",
    "\n",
    "model = SimpleCNN(len(selected_indexes)).to(device)\n",
    "model.load_state_dict(torch.load('./model/cnn-e-extra.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_transformed(test_dataloader, model, selected_indexes=None):\n",
    "    losses = []\n",
    "    y_predict = []\n",
    "    y_true = []\n",
    "\n",
    "    for i, data in enumerate(test_dataloader, 0):\n",
    "        cur_images, cur_features, cur_labels = (data['image'].to(device),\n",
    "                                                data['feature'].to(device),\n",
    "                                                data['label'].to(device))\n",
    "        \n",
    "        # Only use depth and d here\n",
    "        if selected_indexes != None:\n",
    "            cur_features = cur_features[:, selected_indexes]\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(cur_images, cur_features)\n",
    "        loss = criterion(outputs, cur_labels)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        outputs = outputs.cpu().detach().numpy().reshape(-1).tolist()\n",
    "        cur_labels = cur_labels.cpu().detach().numpy().reshape(-1).tolist()\n",
    "#         break\n",
    "\n",
    "#         outputs = [scaler.mean_[2] + i * scaler.scale_[2] for i in outputs]\n",
    "#         cur_labels = [scaler.mean_[2] + i * scaler.scale_[2] for i in cur_labels]\n",
    "\n",
    "        outputs = [e_range * i + e_min for i in outputs]\n",
    "        cur_labels = [e_range * i + e_min for i in cur_labels]\n",
    "\n",
    "        y_predict.extend(outputs)\n",
    "        y_true.extend(cur_labels)\n",
    "        \n",
    "#     print(np.array(y_predict) - np.array(y_true))\n",
    "    \n",
    "    mse = metrics.mean_squared_error(y_true, y_predict)\n",
    "    mae = metrics.mean_absolute_error(y_true, y_predict)\n",
    "    mape = metrics.mean_absolute_percentage_error(y_true, y_predict)\n",
    "    avg_loss = np.mean(losses)\n",
    "    \n",
    "    #print('Test accuracy {:.4f} test avg loss {:.4f}'.format(acc, avg_loss))\n",
    "    \n",
    "#     return mae, avg_loss, y_predict, y_true\n",
    "    return mape, mae, avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the MAPE, MAE, average loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.015000611187080584, 967275.2458268589, 0.0003134536402409069)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model_transformed(train_dataloader, model, selected_indexes=selected_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01839592757431822, 1186589.6101164627, 0.00046326938027050344)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model_transformed(vali_dataloader, model, selected_indexes=selected_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.018526086448772055, 1138635.872358661, 0.00043211622334118666)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model_transformed(test_dataloader, model, selected_indexes=selected_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Naive Baseline Model\n",
    "\n",
    "Finally, we can \"train\" a naive baseline model that uses the average values in the training set for all predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 817/817 [00:00<00:00, 297228.41it/s]\n",
      "100%|█████████████████████████████████████| 273/273 [00:00<00:00, 269422.35it/s]\n",
      "100%|█████████████████████████████████████| 273/273 [00:00<00:00, 351672.29it/s]\n"
     ]
    }
   ],
   "source": [
    "train_features_linear = []\n",
    "vali_features_linear = []\n",
    "test_features_linear = []\n",
    "\n",
    "for i in tqdm(range(train_features.shape[0])):    \n",
    "    train_features_linear.append(train_features[i][1].reshape(-1))\n",
    "    \n",
    "for i in tqdm(range(vali_features.shape[0])):\n",
    "    vali_features_linear.append(vali_features[i][1].reshape(-1))\n",
    "    \n",
    "for i in tqdm(range(test_features.shape[0])):\n",
    "    test_features_linear.append(test_features[i][1].reshape(-1))\n",
    "    \n",
    "train_features_linear = np.vstack(train_features_linear)\n",
    "vali_features_linear = np.vstack(vali_features_linear)\n",
    "test_features_linear = np.vstack(test_features_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_orginal = np.array([e_min + e_range * i for i in train_scores])\n",
    "vali_score_orginal = np.array([e_min + e_range * i for i in vali_scores])\n",
    "test_score_orginal = np.array([e_min + e_range * i for i in test_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3249746499370797"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_absolute_percentage_error(train_score_orginal, np.ones(train_score_orginal.shape) * np.mean(train_score_orginal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29321693808323723"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_absolute_percentage_error(vali_score_orginal, np.ones(vali_score_orginal.shape) * np.mean(train_score_orginal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32342642057320686"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_absolute_percentage_error(test_score_orginal, np.ones(test_score_orginal.shape) * np.mean(train_score_orginal))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
